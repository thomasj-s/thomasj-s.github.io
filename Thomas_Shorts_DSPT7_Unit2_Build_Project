{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thomas_Shorts_DSPT7_Unit2_Sprint3_Assignment1_Machine_Learning_Problems.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP41nON/iL33333JVMJQ9tf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasj-s/thomasj-s.github.io/blob/master/Thomas_Shorts_DSPT7_Unit2_Build_Project\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXE8SgObQ6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e24f6d14-5ce2-4a3a-c1da-489d9da3e8bd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in Hall of Fame dataset\n",
        "\n",
        "hof = pd.read_csv('/content/HallOfFame.csv')\n",
        "hof.head(5)"
      ],
      "execution_count": 945,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playerID</th>\n",
              "      <th>yearid</th>\n",
              "      <th>votedBy</th>\n",
              "      <th>ballots</th>\n",
              "      <th>needed</th>\n",
              "      <th>votes</th>\n",
              "      <th>inducted</th>\n",
              "      <th>category</th>\n",
              "      <th>needed_note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cobbty01</td>\n",
              "      <td>1936</td>\n",
              "      <td>BBWAA</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Player</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ruthba01</td>\n",
              "      <td>1936</td>\n",
              "      <td>BBWAA</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Player</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wagneho01</td>\n",
              "      <td>1936</td>\n",
              "      <td>BBWAA</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Player</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mathech01</td>\n",
              "      <td>1936</td>\n",
              "      <td>BBWAA</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Player</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>johnswa01</td>\n",
              "      <td>1936</td>\n",
              "      <td>BBWAA</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Player</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    playerID  yearid votedBy  ballots  ...  votes  inducted category needed_note\n",
              "0   cobbty01    1936   BBWAA    226.0  ...  222.0         Y   Player         NaN\n",
              "1   ruthba01    1936   BBWAA    226.0  ...  215.0         Y   Player         NaN\n",
              "2  wagneho01    1936   BBWAA    226.0  ...  215.0         Y   Player         NaN\n",
              "3  mathech01    1936   BBWAA    226.0  ...  205.0         Y   Player         NaN\n",
              "4  johnswa01    1936   BBWAA    226.0  ...  189.0         Y   Player         NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 945
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLQsk-vsmHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "802fa3e1-61c0-4881-c5cd-b78687e8f577"
      },
      "source": [
        "# Check which columns have null and hof shape\n",
        "\n",
        "hof.isnull().sum(), hof.shape"
      ],
      "execution_count": 946,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(playerID          0\n",
              " yearid            0\n",
              " votedBy           0\n",
              " ballots         193\n",
              " needed          350\n",
              " votes           193\n",
              " inducted          0\n",
              " category          0\n",
              " needed_note    3963\n",
              " dtype: int64, (4120, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 946
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCJv-Cjs_z9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f02336ab-a567-491a-996e-4b4f2d9826e4"
      },
      "source": [
        "# Drop 'needed_note' column, then drop rows with missing data.\n",
        "# We drop 'needed_note' column first so that when we apply .dropna,\n",
        "# we don't drop 3963 rows.\n",
        "\n",
        "hof = hof.drop(columns='needed_note')\n",
        "hof = hof.dropna(axis=0, how='any')\n",
        "hof.shape"
      ],
      "execution_count": 947,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3770, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 947
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ribe-cJ91aHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0369c65-e586-4d28-cbc7-33a323982565"
      },
      "source": [
        "# Create list with unique player values for reference on how long\n",
        "# our final 'first ballot' dataset list should be.\n",
        "\n",
        "hof_names = list(hof['playerID'].unique())\n",
        "len(hof_names)"
      ],
      "execution_count": 948,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 948
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U41VmJpEGoP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aca901ed-ef20-4350-c9ed-89982e415972"
      },
      "source": [
        "# Use drop_duplicates to drop rows where a players name has appeared\n",
        "# a second, third, fourth etc. time.  This ensures that our list is \n",
        "# comprised of only first ballot entries. We confirm this by checking the\n",
        "# shape against the list in the previous cell of unique values.\n",
        "\n",
        "\n",
        "hof = hof.drop_duplicates(subset='playerID', keep='first')\n",
        "hof.shape"
      ],
      "execution_count": 949,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1151, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 949
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAT66xsTh2zC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0d3031cc-3b82-436c-80ee-cb0bab8cd207"
      },
      "source": [
        "# Check distribution of our target value, 'Inducted'\n",
        "\n",
        "hof['inducted'].value_counts(normalize=True)"
      ],
      "execution_count": 950,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    0.95656\n",
              "Y    0.04344\n",
              "Name: inducted, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 950
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJgoIH-HhE4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----------  Our hall of fame dataset is clean and ready for use in extracting  --------\n",
        "# ----------  batting stats for first time ballot players.          --------"
      ],
      "execution_count": 951,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLAilIXBhrnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our tagret is the 'yes' class of the 'inducted' column.  Choosing an \n",
        "# evaluation metric for this is difficult as we have very unbalanced classes.\n",
        "\n",
        "# We will lean toward precision and f-score.  "
      ],
      "execution_count": 952,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J02rSPOp0hG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "de91d333-7934-4ae0-bc8b-9077ff8e2a3b"
      },
      "source": [
        "# Load in / preview 'Batting' dataset\n",
        "\n",
        "batting = pd.read_csv('/content/Batting.csv')\n",
        "batting.head()"
      ],
      "execution_count": 953,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playerID</th>\n",
              "      <th>yearID</th>\n",
              "      <th>stint</th>\n",
              "      <th>teamID</th>\n",
              "      <th>lgID</th>\n",
              "      <th>G</th>\n",
              "      <th>AB</th>\n",
              "      <th>R</th>\n",
              "      <th>H</th>\n",
              "      <th>2B</th>\n",
              "      <th>3B</th>\n",
              "      <th>HR</th>\n",
              "      <th>RBI</th>\n",
              "      <th>SB</th>\n",
              "      <th>CS</th>\n",
              "      <th>BB</th>\n",
              "      <th>SO</th>\n",
              "      <th>IBB</th>\n",
              "      <th>HBP</th>\n",
              "      <th>SH</th>\n",
              "      <th>SF</th>\n",
              "      <th>GIDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abercda01</td>\n",
              "      <td>1871</td>\n",
              "      <td>1</td>\n",
              "      <td>TRO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>addybo01</td>\n",
              "      <td>1871</td>\n",
              "      <td>1</td>\n",
              "      <td>RC1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25</td>\n",
              "      <td>118.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allisar01</td>\n",
              "      <td>1871</td>\n",
              "      <td>1</td>\n",
              "      <td>CL1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29</td>\n",
              "      <td>137.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allisdo01</td>\n",
              "      <td>1871</td>\n",
              "      <td>1</td>\n",
              "      <td>WS3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27</td>\n",
              "      <td>133.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ansonca01</td>\n",
              "      <td>1871</td>\n",
              "      <td>1</td>\n",
              "      <td>RC1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25</td>\n",
              "      <td>120.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    playerID  yearID  stint teamID lgID   G  ...   SO  IBB  HBP  SH  SF  GIDP\n",
              "0  abercda01    1871      1    TRO  NaN   1  ...  0.0  NaN  NaN NaN NaN   NaN\n",
              "1   addybo01    1871      1    RC1  NaN  25  ...  0.0  NaN  NaN NaN NaN   NaN\n",
              "2  allisar01    1871      1    CL1  NaN  29  ...  5.0  NaN  NaN NaN NaN   NaN\n",
              "3  allisdo01    1871      1    WS3  NaN  27  ...  2.0  NaN  NaN NaN NaN   NaN\n",
              "4  ansonca01    1871      1    RC1  NaN  25  ...  1.0  NaN  NaN NaN NaN   NaN\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 953
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXIv-7SGu4S8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "de1b4d09-d9f0-4926-861e-58716a173002"
      },
      "source": [
        "# Check for null\n",
        "\n",
        "batting.isnull().sum(), batting.shape\n"
      ],
      "execution_count": 954,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(playerID        0\n",
              " yearID          0\n",
              " stint           0\n",
              " teamID          0\n",
              " lgID          737\n",
              " G               0\n",
              " AB           5149\n",
              " R            5149\n",
              " H            5149\n",
              " 2B           5149\n",
              " 3B           5149\n",
              " HR           5149\n",
              " RBI          5573\n",
              " SB           6449\n",
              " CS          28603\n",
              " BB           5149\n",
              " SO          12987\n",
              " IBB         41712\n",
              " HBP          7959\n",
              " SH          11487\n",
              " SF          41181\n",
              " GIDP        31257\n",
              " dtype: int64, (101332, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 954
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2BleEousjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Before imputing or dropping any data, lets reduce our data set to only the stats\n",
        "# of players who were inducted into the hall of fame.  This will give us \n",
        "# a better picture of how much missing data we will actually be dealing with.\n",
        "\n",
        "hof_batting = [[]]\n",
        "\n",
        "for x in hof_names:\n",
        "  for y in batting.index:\n",
        "    if x == batting['playerID'][y]:\n",
        "      hof_batting.append(batting.iloc[y])\n",
        "\n",
        "hof_batting = pd.DataFrame(hof_batting)\n",
        "hof_batting.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYI6HbiGb8Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-assign columns names / drop first row and reset index\n",
        "\n",
        "hof_batting.columns = batting.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_08j5zceS8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hof_batting1 = hof_batting.drop(0)\n",
        "hof_batting1.reset_index(inplace=True)\n",
        "hof_batting1.drop(columns='index', inplace=True)\n",
        "hof_batting1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFwqdBvRReEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for null data\n",
        "\n",
        "hof_batting1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chYP5mKTgg1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a column for batting average\n",
        "\n",
        "hof_batting1['Avg.'] = hof_batting1['H'] / hof_batting1['AB']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqNdoakIrVol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hof_batting1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0RaBMl5nHoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write function to derive career averages for players with more than\n",
        "# zero at bats.\n",
        "\n",
        "def get_average(df, playerID):\n",
        "\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "\n",
        "  if sum(df1['AB']) > 0:\n",
        "    career_average = sum(df1['H']) / sum(df1['AB'])\n",
        "\n",
        "  else:\n",
        "    career_average = 0\n",
        "\n",
        "  return career_average"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTe92ZtznrL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use our function to get a list of career averages, one for every player in our\n",
        "# hall of fame player list.\n",
        "\n",
        "averages = []\n",
        "\n",
        "for x in hof_names:\n",
        "  averages.append(get_average(hof_batting1, x))\n",
        "\n",
        "len(averages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceAtCgTzqlAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new column for career averages\n",
        "\n",
        "hof['career_average'] = averages\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXtXlZmfq506",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our Hall of fame player list includes batters with 0 career at bats, which gave our function\n",
        "# a difficult time calculating batting averages.  Upon further inspection, we see that \n",
        "# pitchers ended up on this list with 0 career at bats, we will drop those with 0\n",
        "# career average, as our function determines they are a pitcher, or a manager and not\n",
        "# a position player.\n",
        "\n",
        "# We drop 176 players with a 0 average.  Lets re-check our targer distribution.\n",
        "\n",
        "hof = hof[hof['career_average'] > 0]\n",
        "len(hof), hof['inducted'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDWoYs42A5Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we have dropped values from our 'hof' dataset, we have to be sure that\n",
        "# we drop those same names from the 'hof_names' list, as we are using for loops and our \n",
        "# 'hof_names' list to iterate over and create columns for our dataset.  This will not\n",
        "# work if these two are not the same length and in the same order in terms of \n",
        "# player ID.\n",
        "\n",
        "hof['category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67ZDY7_5Dspa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop managers and pioneer / executives from our data.\n",
        "\n",
        "hof = hof[hof['category'] == 'Player']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzzg_D_1GNQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-define 'hof_names' list by using our current 'playerID' column\n",
        "# in the 'hof' dataset.  This keeps them having the same length, order, and\n",
        "# values.\n",
        "\n",
        "hof_names = hof['playerID']\n",
        "len(hof_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvtmyE84G4VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in pitching dataset\n",
        "\n",
        "pitching = pd.read_csv('/content/Pitching.csv')\n",
        "len(pitching)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmvcRxaHTDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use a similar method as earlier in the notebook to drop duplicates\n",
        "# from our 'pitching' dataset.  This will speed up our for loops.\n",
        "\n",
        "pitching.drop_duplicates(subset='playerID', keep='first', inplace=True)\n",
        "len(pitching)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1OdO3bLFOts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 'pitching' dataset to filter out players by id who would have not been voted in\n",
        "# according to their offensive stats, such as batting average.\n",
        "\n",
        "pitchers_to_drop = [[]]\n",
        "\n",
        "for x in hof_names:\n",
        "  for y in pitching.index:\n",
        "    if pitching['playerID'][y] == x:\n",
        "      pitchers_to_drop.append(x)\n",
        "\n",
        "len(pitchers_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzSp3-P4I-Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seems like some of our position players may appear on our pitchers_to_drop\n",
        "# list also, not what we want.  Now we have to determine which of our pitchers_to_drop\n",
        "# should be kept.  Lets use batting average as a way of narrowing down our \n",
        "# pitchers_to_drop\n",
        "\n",
        "actual_pitchers_to_drop = [[]]\n",
        "\n",
        "for x in pitchers_to_drop:\n",
        "  for y in hof.index:\n",
        "    if hof['playerID'][y] == x and hof['career_average'][y] <= .239:\n",
        "      actual_pitchers_to_drop.append(x)\n",
        "\n",
        "len(actual_pitchers_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxPaiw0MpH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop players on 'actual_players_to_drop' list from our 'hof' dataset\n",
        "\n",
        "for x in actual_pitchers_to_drop:\n",
        "  for y in hof.index:\n",
        "    if hof['playerID'][y] == x:\n",
        "      hof = hof.drop(y)\n",
        "\n",
        "len(hof)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPt4g3ckO_bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-define our 'hof_names' list again.  We will need to do this every time before \n",
        "# we use this list to iterate over our data to create stats / features.\n",
        "\n",
        "hof_names = hof['playerID']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHE2NuzMr9KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a function to calculate career hits and average # of hits per season.\n",
        "\n",
        "def get_total_hits(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  career_hits = sum(df1['H'])\n",
        "  return career_hits\n",
        "\n",
        "def average_hits_per_season(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  hits_per_season = sum(df1['H']) / len(df1)\n",
        "  return hits_per_season\n",
        "\n",
        "career_hits_list = []\n",
        "hits_per_season_list = []\n",
        "\n",
        "for x in hof_names:\n",
        "  career_hits_list.append(get_total_hits(hof_batting1, x))\n",
        "  hits_per_season_list.append(average_hits_per_season(hof_batting1, x))\n",
        "\n",
        "hof['hits_per_season'] = hits_per_season_list\n",
        "hof['career_hits'] = career_hits_list\n",
        "\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXiV7gyBQsYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check again for missing data now that we are nearing a point where we know how much\n",
        "# we would realisticly have to work with.\n",
        "\n",
        "# Absolutely beautiful.\n",
        "\n",
        "hof.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDwATaqZYtw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create for loop to reduce our 'hof_batting1' dataset to only players in our\n",
        "# 'hof_names' list to speed up our for loops\n",
        "\n",
        "hof_batting = [[]]\n",
        "\n",
        "for x in hof_names:\n",
        "  for y in hof_batting1.index:\n",
        "    if hof_batting1['playerID'][y] == x:\n",
        "      hof_batting.append(hof_batting1.iloc[y])\n",
        "\n",
        "hof_batting = pd.DataFrame(hof_batting)\n",
        "hof_batting.head(), len(hof_batting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKcn00pOtEjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define column names, drop blank 0 index, reset index, and drop index column.\n",
        "# Our batting data is now only our hall of fame players.\n",
        "\n",
        "hof_batting.columns = hof_batting1.columns\n",
        "hof_batting = hof_batting.drop(0)\n",
        "hof_batting.reset_index(inplace=True)\n",
        "hof_batting.drop(columns='index', inplace=True)\n",
        "hof_batting.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzW_lb9aTAOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -Retroactively checking a column for value counts to fix a function- \n",
        "\n",
        "hof_batting['lgID'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atDCn19hUPPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -Retroactively lumping values other than 'AL' and 'NL'\n",
        "# -into an 'other' category.\n",
        "\n",
        "hof_batting = hof_batting.replace({'AA':'other', 'FL':'other', 'PL':'other', 'UA':'other'})\n",
        "hof_batting['lgID'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UarCD6EnrWu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hof_batting.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8SsoG6CoLnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -Retroactively changing missing values in 'lgID' column\n",
        "# to 'missing'\n",
        "\n",
        "hof_batting['lgID'] = hof_batting['lgID'].fillna('missing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1QCX2X9WzfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Might as well re-check our target distribution.\n",
        "\n",
        "hof['inducted'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7aI34Y3s-tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets re-evaluate which features to drop from our data before continuing with\n",
        "# new features.\n",
        "\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBdQrSoxt50o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can drop 'playerID' once we are done feature engineering.\n",
        "# Drop 'votedBy', as there is not enough distribution of values\n",
        "# Drop 'ballots', 'needed', and 'votes', as these seem like leaky features\n",
        "# Drop 'category' as there is only one value\n",
        "\n",
        "hof = hof.drop(columns = ['votedBy', 'ballots', 'needed', 'votes', 'category'])\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo3ArFfAuyok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we have a much more workable dataset, lets get an idea of the stats \n",
        "# we will want to add to our 'hof' dataset\n",
        "\n",
        "# Career HR, HR's per season\n",
        "# Career RBI, RBI per season\n",
        "# Slugging percentage (1B + 2x2B + 3x3B + 4xHR) / AB\n",
        "# Number of teams played on (categorical: 1, 2, 3+)\n",
        "# Leagues played in (categorical: AL, NL, both, missing)\n",
        "# Number of seasons played (10 or less, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20+)\n",
        "# Average games per season (categorical: 139 and less, 140-145, 146-150, 151-155, 155+ )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwtq5i5iwsDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write functions for Career HRs, and average HRs per season\n",
        "\n",
        "def get_career_HRs(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  career_HRs = sum(df1['HR'])\n",
        "  return career_HRs\n",
        "\n",
        "def get_HRs_per_season(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  HRs_per_season = sum(df1['HR']) / len(df1)\n",
        "  return HRs_per_season\n",
        "\n",
        "# Write functions for RBIs / RBIs per season\n",
        "\n",
        "def get_career_RBIs(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  career_RBIs = sum(df1['RBI'])\n",
        "  return career_RBIs\n",
        "\n",
        "def get_RBIs_per_season(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  RBIs_per_season = sum(df1['RBI']) / len(df1)\n",
        "  return RBIs_per_season\n",
        "\n",
        "# Function for slugging percentage.\n",
        "\n",
        "def get_career_slugging_pct(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  singles = sum(df1['H']) - (sum(df1['2B']) + sum(df1['3B']) + sum(df1['HR']))\n",
        "  doubles = sum(df1['2B'])\n",
        "  triples = sum(df1['3B'])\n",
        "  HRs = sum(df1['HR'])\n",
        "  ABs = sum(df1['AB'])\n",
        "  slugging_pct = ((singles) + (2 * doubles) + (3 * triples) + (4 * HRs)) / ABs\n",
        "  return slugging_pct\n",
        "\n",
        "# Function for # of teams played on\n",
        "\n",
        "def get_no_of_teams(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  df1.drop_duplicates(subset='teamID', keep='first', inplace=True)\n",
        "  if len(df1['teamID']) == 1:\n",
        "    no_teams_played_on = 1\n",
        "  if len(df1['teamID']) == 2:\n",
        "    no_teams_played_on = 2\n",
        "  if len(df1['teamID']) >= 3:\n",
        "    no_teams_played_on = '3+' \n",
        "  return no_teams_played_on\n",
        "\n",
        "# Function for leagues played in\n",
        "\n",
        "def get_leagues_played_in(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  df1.drop_duplicates(subset='lgID', keep='first', inplace=True)\n",
        "  s = set(df1['lgID'])\n",
        "  if len(s) == 1:\n",
        "    if 'AL' in set(s):\n",
        "      leagues_played_in = 'AL'\n",
        "    if 'NL' in set(s):\n",
        "      leagues_played_in = 'NL'\n",
        "    if 'other' in set(s):\n",
        "      leagues_played_in = 'other'\n",
        "    if 'missing' in set(s):\n",
        "      leagues_played_in = 'missing'\n",
        "  if len(s) == 2:\n",
        "    if 'AL' in set(s) and 'NL' in set(s):\n",
        "      leagues_played_in = 'both'\n",
        "    if 'AL' in set(s) and 'other' in set(s):\n",
        "      leagues_played_in = 'AL'\n",
        "    if 'NL' in set(s) and 'other' in set(s):\n",
        "      leagues_played_in = 'NL'\n",
        "    if 'AL' in set(s) and 'missing' in set(s):\n",
        "      leagues_played_in = 'AL'\n",
        "    if 'NL' in set(s) and 'missing' in set(s):\n",
        "      leagues_played_in = 'NL'\n",
        "    if 'other' in set(s) and 'missing' in set(s):\n",
        "      leagues_played_in = 'other'\n",
        "  if len(s) == 3:\n",
        "    if 'AL' in set(s) and 'NL' in set(s):\n",
        "      leagues_played_in = 'both'\n",
        "    if 'AL' in set(s) and 'NL' not in set(s):\n",
        "      leagues_played_in = 'AL'\n",
        "    if 'NL' in set(s) and 'AL' not in set(s):\n",
        "      leagues_played_in = 'NL'\n",
        "  if len(s) == 4:\n",
        "    leagues_played_in = 'both'\n",
        "  return leagues_played_in\n",
        "\n",
        "# Use for loops for apply our functions and add features to our hof dataset\n",
        "\n",
        "career_HRs = []\n",
        "HRs_per_season = []\n",
        "career_RBIs = []\n",
        "RBIs_per_season = []\n",
        "slugging_pct = []\n",
        "no_teams_played_on = []\n",
        "leagues_played_in = []\n",
        "\n",
        "for x in hof_names:\n",
        "  career_HRs.append(get_career_HRs(hof_batting, x))\n",
        "  HRs_per_season.append(get_HRs_per_season(hof_batting, x))\n",
        "  career_RBIs.append(get_career_RBIs(hof_batting, x))\n",
        "  RBIs_per_season.append(get_RBIs_per_season(hof_batting, x))\n",
        "  slugging_pct.append(get_career_slugging_pct(hof_batting, x))\n",
        "  no_teams_played_on.append(get_no_of_teams(hof_batting, x))\n",
        "  leagues_played_in.append(get_leagues_played_in(hof_batting, x))\n",
        "\n",
        "hof['career HRs'] = career_HRs\n",
        "hof['HRs per season'] = HRs_per_season\n",
        "hof['career RBIs'] = career_RBIs\n",
        "hof['RBIs per season'] = RBIs_per_season\n",
        "hof['career slugging pct'] = slugging_pct\n",
        "hof['No. teams played on'] = no_teams_played_on\n",
        "hof['leagues played in'] = leagues_played_in\n",
        "\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55d-XWI_VMps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for total number of seasons played.  We will bin these values later.\n",
        "\n",
        "def get_total_seasons_played(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  seasons_played = len(df1)\n",
        "  return seasons_played\n",
        "\n",
        "total_seasons_played = []\n",
        "\n",
        "for x in hof_names:\n",
        "  total_seasons_played.append(get_total_seasons_played(hof_batting, x))\n",
        "\n",
        "hof['seasons played'] = total_seasons_played"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_Fh3-yYYOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for games played per season\n",
        "\n",
        "def get_games_per_season(df, playerID):\n",
        "  df1 = df[df['playerID'] == playerID]\n",
        "  total_games = sum(df1['G'])\n",
        "  avg_games_per_season = total_games / len(df1)\n",
        "  return avg_games_per_season\n",
        "\n",
        "games_per_season = []\n",
        "\n",
        "for x in hof_names:\n",
        "  games_per_season.append(get_games_per_season(hof_batting, x))\n",
        "\n",
        "hof['avg games per season'] = games_per_season"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAmNCMqVZko2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(hof['avg games per season'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CriJOghphPxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(hof['seasons played'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV9ZThlGZx1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bin our 'seasons played' and 'avg games per season' columns to make them categorical.\n",
        "\n",
        "hof['seasons played bins'] = pd.cut(hof['seasons played'], bins=[-1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 40], \n",
        "                                    labels=['10 or less', 11, 12, 13, 14, 15, 16, 17, 18, 19, '20+'])\n",
        "\n",
        "hof = hof.drop(columns = 'seasons played')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoCFuDDgnF0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bin our 'average games played per season' column to make it categorical.\n",
        "\n",
        "hof['avg games per season'] = pd.cut(hof['avg games per season'], bins = [-1, 75, 80, 95, 110, 125, 140, 155, 180 ],\n",
        "                                     labels = ['0-75', '76-80', '81-95', '96-110', '111-125', '126-140', '141-155', '155+'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tcAc301oZ2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our data is ready to begin modeling.  We have clean data with no missing values, a mix of categorical\n",
        "# and numeric variables, and enought data to train on.  Freakin awesome.\n",
        "\n",
        "hof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpluHFNy2Irj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53vkmpdE2O0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------- Start Modeling ---------------------#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1227bf--2PHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeXy5JPG2W5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets import a bunch / re-import a bunch of stuff we know we are going to need\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "from sklearn.metrics import plot_confusion_matrix, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, plot_precision_recall_curve\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.cluster import KMeans \n",
        "!pip install pdpbox\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot, pdp_interact, pdp_interact_plot\n",
        "!pip install eli5\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import f_classif, SelectKBest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wmfbpt25UyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets make a basic pipeline to see what we can do with a first model.\n",
        "\n",
        "train, val = train_test_split(hof, test_size = .32, stratify=hof['inducted'], random_state=42)\n",
        "val, test = train_test_split(val, test_size = .3, stratify=val['inducted'], random_state=42)\n",
        "\n",
        "target = 'inducted'\n",
        "\n",
        "xtrain = train.drop(columns=[target, 'playerID', 'yearid'])\n",
        "ytrain = train[target]\n",
        "ytrain = ytrain.replace({'Y':1, 'N':0})\n",
        "\n",
        "xval = val.drop(columns=[target, 'playerID', 'yearid'])\n",
        "yval = val[target]\n",
        "yval = yval.replace({'Y':1, 'N':0})\n",
        "\n",
        "xtest = test.drop(columns=[target, 'playerID', 'yearid'])\n",
        "ytrue = test[target]\n",
        "ytrue = ytrue.replace({'Y':1, 'N':0})\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    RandomForestClassifier(class_weight={0:1, 1:3})\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fhu9inJPQWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create our encoded and transformed data for future use\n",
        "\n",
        "encoder = ce.OrdinalEncoder()\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "xtrain_encoded = encoder.fit_transform(xtrain)\n",
        "xtrain_transformed = imputer.fit_transform(xtrain_encoded)\n",
        "\n",
        "xval_encoded = encoder.fit_transform(xval)\n",
        "xval_transformed = imputer.fit_transform(xval_encoded)\n",
        "\n",
        "xtest_encoded = encoder.fit_transform(xtest)\n",
        "xtest_transformed = imputer.fit_transform(xtest_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnQcNso1DrX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check shapes\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8CpJ-pKRHDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a cv_score for our first model\n",
        "\n",
        "cv_score = cross_val_score(pipeline, xtrain, ytrain, cv=5, scoring='precision')\n",
        "\n",
        "np.mean(cv_score), cv_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_YrM2i9AHun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit pipeline to our train data\n",
        "\n",
        "pipeline.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vKLX02f2HAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get an accuracy / precision ratings on our first models val score\n",
        "\n",
        "# We get an accuracy that beats our baseline. Hooray!\n",
        "\n",
        "predicted1 = pipeline.predict(xval)\n",
        "accuracy1 = accuracy_score(yval, predicted1)\n",
        "precision1 = precision_score(yval, predicted1)\n",
        "recall1 = recall_score(yval, predicted1)\n",
        "f11 = f1_score(yval, predicted1)\n",
        "\n",
        "print(f'First model accuracy : {accuracy1}.'),\n",
        "print(f'First model precision : {precision1}.'),\n",
        "print(f'First model recall : {recall1}.'),\n",
        "print(f'First model f1 : {f11}.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjASGph0QsJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a predicted probability with custom threshold.  We\n",
        "# will use this to derive our accuracy, precision, and recall\n",
        "# scores from our first model.\n",
        "\n",
        "# Our precision is really good also considering the small amount of positive\n",
        "# observations.  This is the main metric we will be using to drive our model.\n",
        "# In the context of making a sports betting model, we only wany to put money\n",
        "# down if we are very sure it is a win.  With this model, we could feel more combfortable\n",
        "# betting on an 'N' than wth baseline, which was already very high.  I also wouldn't be too\n",
        "# afraid of putting money on a positive prediction...as long as the return was 1.25\n",
        "\n",
        "threshold = .5\n",
        "\n",
        "predicted_proba = pipeline.predict_proba(xval)\n",
        "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
        "precision = precision_score(yval, predicted)\n",
        "recall = recall_score(yval, predicted)\n",
        "f1 = f1_score(yval, predicted)\n",
        "precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3AXSeuUyOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check permutation importances\n",
        "\n",
        "\n",
        "permuter = PermutationImportance (\n",
        "    pipeline.named_steps['randomforestclassifier'],\n",
        "    scoring='precision',\n",
        "    n_iter=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(xval_transformed, yval)\n",
        "feature_names = xval.columns.tolist()\n",
        "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKb57V_YdTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjakAlRf3CJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets look at a confusion matrix\n",
        "\n",
        "plot_confusion_matrix(pipeline, xval, yval, values_format='.0f', xticks_rotation = 'vertical')\n",
        "plt.savefig(\"build_project_2_vis_1.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-fTKXiX_Fpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ Import SMOTE ########################################################\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "oversample = SMOTE(sampling_strategy=.5, k_neighbors=2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SumoTKCpAMv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SMOTE to balance class distribution.\n",
        "# set up our new arrays as dataframes\n",
        "\n",
        "xtrain_res, ytrain_res = oversample.fit_resample(xtrain_transformed, ytrain)\n",
        "xtrain_res.shape, ytrain_res.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nczNXIFJLw3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create resampled dataframe for x train\n",
        "\n",
        "xtrain_res = pd.DataFrame(xtrain_res)\n",
        "xtrain_res.columns = xtrain.columns\n",
        "xtrain_res.reset_index(inplace=True)\n",
        "xtrain_res.drop(columns='index', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_e2SlLmOM4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up resampled train target dataframe\n",
        "\n",
        "ytrain_res = pd.DataFrame(ytrain_res)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQQzlaRgSIlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check our target distribution\n",
        "\n",
        "ytrain_res[0].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndkIeS6PcZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(xtrain_res), len(ytrain_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75OO3sNWaIAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define pipeline for use with SMOTE data\n",
        "\n",
        "pipeline2 = make_pipeline(\n",
        "    encoder,\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    RandomForestClassifier()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h91da40OGPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tune Hyperameters for our second model\n",
        "\n",
        "#param_grid = {\n",
        "#   'randomforestclassifier__max_depth': range(0,8),\n",
        "#   'randomforestclassifier__min_samples_leaf': range(0,10),\n",
        "#   'randomforestclassifier__min_samples_split': range(0,10)\n",
        "#}\n",
        "\n",
        "#search = GridSearchCV(\n",
        "#   estimator = pipeline2,\n",
        "#   param_grid = param_grid,\n",
        "#   scoring = 'precision',\n",
        "#   n_jobs=-1,\n",
        "#   verbose=3,\n",
        "#   cv=5\n",
        "#)\n",
        "\n",
        "#search = search.fit(xtrain_res, ytrain_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM2o-cq_tpAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4SSuLk2uRTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Redefine pipeline with best params.\n",
        "\n",
        "pipeline2 = make_pipeline(\n",
        "    encoder,\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    RandomForestClassifier(max_depth=7, min_samples_leaf=3, min_samples_split=7, class_weight={0:1, 1:2})  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LowDOfxI7TUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model to SMOTE'd data\n",
        "\n",
        "pipeline2.fit(xtrain_res, ytrain_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJ2HLXfogLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare evaluation metrics for our first and second model.\n",
        "\n",
        "threshold = .5\n",
        "\n",
        "predicted_proba2 = pipeline2.predict_proba(xval)\n",
        "predicted2 = (predicted_proba2 [:,1] >= threshold).astype('int')\n",
        "accuracy2 = accuracy_score(yval, predicted2)\n",
        "precision2 = precision_score(yval, predicted2)\n",
        "recall2 = recall_score(yval, predicted2)\n",
        "f12 = f1_score(yval, predicted2)\n",
        "\n",
        "print(f'First model accuracy : {accuracy1}.'),\n",
        "print(f'First model precision : {precision1}.'),\n",
        "print(f'First model recall : {recall1}.'),\n",
        "print(f'First model f1 : {f11}.'),\n",
        "\n",
        "print(f'Second model accuracy : {accuracy2}.'),\n",
        "print(f'Second model precision : {precision2}.'),\n",
        "print(f'Second model recall : {recall2}.'),\n",
        "print(f'Second model f1 : {f12}.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhjrqCcIlV66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets run them on our test data...... the moment of truth\n",
        "\n",
        "threshold = .5\n",
        "\n",
        "test_proba1 = pipeline.predict_proba(xtest)\n",
        "test_proba2 = pipeline2.predict_proba(xtest)\n",
        "\n",
        "test_pred1 = (test_proba1[:,1] >= threshold).astype('int')\n",
        "test_pred2 = (test_proba2[:,1] >= threshold).astype('int')\n",
        "\n",
        "test_accuracy1 = accuracy_score(ytrue, test_pred1)\n",
        "test_precision1 = precision_score(ytrue, test_pred1)\n",
        "test_recall1 = recall_score(ytrue, test_pred1)\n",
        "test_f11 = f1_score(ytrue, test_pred1)\n",
        "\n",
        "test_accuracy2 = accuracy_score(ytrue, test_pred2)\n",
        "test_precision2 = precision_score(ytrue, test_pred2)\n",
        "test_recall2 = recall_score(ytrue, test_pred2)\n",
        "test_f12 = f1_score(ytrue, test_pred2)\n",
        "\n",
        "print(f'First model test accuracy : {test_accuracy1}'),\n",
        "print(f'First model test precision : {test_precision1}'),\n",
        "print(f'First model test recall: {test_recall1}'),\n",
        "print(f'First model test f-1: {test_f11}'),\n",
        "\n",
        "print(f'Second model test accuracy : {test_accuracy2}'),\n",
        "print(f'Second model test precision : {test_precision2}'),\n",
        "print(f'Second model test recall: {test_recall2}'),\n",
        "print(f'Second model test f-1: {test_f12}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0X7LZASo8r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yes_test = []\n",
        "\n",
        "for x in ytrue:\n",
        "  if x == 1:\n",
        "    yes_test.append(1)\n",
        "\n",
        "sum(yes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJc8G2RnfLPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In summary, we have two models.  One, that is fit to our original data and is\n",
        "# more generalized, performing more consistently, and a second model trained on \n",
        "# SMOTE'd data that ended up performing better on our test data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i4n-KtWgKbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets plot an AUC curve to compare our models\n",
        "\n",
        "# Print and compare roc scores for our two models.  We expect\n",
        "# Model 1 to have the best roc\n",
        "\n",
        "\n",
        "auc1 = roc_auc_score(yval, predicted1)\n",
        "auc2 = roc_auc_score(yval, predicted2)\n",
        "\n",
        "print(f'First model AUC : {auc1}'),\n",
        "print(f'Second model AUC : {auc2}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHoSJLXX4lV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-define our predicted proba for use in an ROC curve plot\n",
        "\n",
        "predicted_proba1_2 = predicted_proba2 = pipeline.predict_proba(xval)[:,-1]\n",
        "predicted_proba2_2 = predicted_proba2 = pipeline2.predict_proba(xval)[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjl_6wUliCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive our tpr, frp, and thresholds for both models\n",
        "\n",
        "fp1, tp1, thresholds1 = roc_curve(yval, predicted_proba1_2)\n",
        "fp2, tp2, thresholds2 = roc_curve(yval, predicted_proba2_2)\n",
        "\n",
        "auc_df1 = pd.DataFrame({\n",
        "    'False Poitive Rate': fp1,\n",
        "    'True Positive Rate': tp1,\n",
        "    'Threshold': thresholds1\n",
        "})\n",
        "\n",
        "auc_df2 = pd.DataFrame({\n",
        "    'False Poitive Rate': fp2,\n",
        "    'True Positive Rate': tp2,\n",
        "    'Threshold': thresholds2\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8PYvLbym7S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot it out\n",
        "\n",
        "# This curve, along with our AOC score, indicates that our pre-smote model\n",
        "# is better overall model.  Our second, SMOTE'd model, requires a higher false\n",
        "# positive (recall) to match our first models true positive (precision)\n",
        "\n",
        "plt.scatter(fp1, tp1)\n",
        "plt.plot(fp1, tp1)\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate');\n",
        "\n",
        "plt.scatter(fp2, tp2)\n",
        "plt.plot(fp2, tp2);\n",
        "\n",
        "plt.savefig(\"build_project_2_vis_4.jpg\")\n",
        "\n",
        "plt.legend(['First Model', 'Second Model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55JmMmh0jiY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "prc1 = plot_precision_recall_curve(pipeline, xval, yval)\n",
        "\n",
        "plt.savefig(\"build_project_2_vis_6.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zprqena0-Xou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "prc1 = plot_precision_recall_curve(pipeline, xval, yval)\n",
        "plt.savefig(\"build_project_2_vis_5.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWOdVqmZRqYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dist plot to show how SMOTE effects feature distribution\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "\n",
        "sns.distplot(xtrain['career_hits'])\n",
        "sns.distplot(xtrain_res['career_hits'])\n",
        "\n",
        "plt.savefig(\"build_project_2_vis_3.jpg\")\n",
        "plt.title('Career hits distribution: SMOTE vs. pre-SMOTE data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRTI24_zKAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(xtrain['career HRs'])\n",
        "sns.distplot(xtrain_res['career HRs'])\n",
        "\n",
        "plt.title('Career Home Runs distribution: SMOTE vs. pre-SMOTE data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAKVK8b97-rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Rlbx1TSU9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a visualization from each of our forests for comparison\n",
        "\n",
        "estimator = pipeline.named_steps['randomforestclassifier'].estimators_[5]\n",
        "\n",
        "export_graphviz(estimator, out_file='tree.dot', \n",
        "                feature_names = xtrain.columns,\n",
        "                class_names = ['no', 'yes'],\n",
        "                rounded = True, proportion = False, \n",
        "                precision = 2, filled = True)\n",
        "\n",
        "# Convert to png using system command (requires Graphviz)\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
        "\n",
        "# Display in jupyter notebook\n",
        "from IPython.display import Image\n",
        "Image(filename = 'tree.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZe7wQiqbgvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = pipeline2.named_steps['randomforestclassifier'].estimators_[5]\n",
        "\n",
        "export_graphviz(estimator, out_file='tree.dot', \n",
        "                feature_names = xtrain.columns,\n",
        "                class_names = ['no', 'yes'],\n",
        "                rounded = True, proportion = False, \n",
        "                precision = 2, filled = True)\n",
        "\n",
        "# Convert to png using system command (requires Graphviz)\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
        "\n",
        "# Display in jupyter notebook\n",
        "from IPython.display import Image\n",
        "Image(filename = 'tree.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcPlRjIH8A2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wrzJpc8CLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(pipeline2, xval, yval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lxMnTW_awdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}